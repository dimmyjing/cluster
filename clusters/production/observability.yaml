# yaml-language-server: $schema=https://raw.githubusercontent.com/yannh/kubernetes-json-schema/refs/heads/master/v1.31.1/namespace-v1.json
apiVersion: v1
kind: Namespace
metadata:
  name: observability
---
# yaml-language-server: $schema=https://raw.githubusercontent.com/fluxcd-community/flux2-schemas/refs/heads/main/helmrepository-source-v1.json
apiVersion: source.toolkit.fluxcd.io/v1
kind: HelmRepository
metadata:
  name: clickstack-repo
  namespace: observability
spec:
  interval: 1m0s
  url: https://hyperdxio.github.io/helm-charts
---
# yaml-language-server: $schema=https://raw.githubusercontent.com/fluxcd-community/flux2-schemas/refs/heads/main/helmrelease-helm-v2.json
# https://artifacthub.io/packages/helm/hdx-oss-v2/clickstack
# https://github.com/hyperdxio/helm-charts/blob/main/charts/clickstack/values.yaml
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: clickstack-release
  namespace: observability
spec:
  interval: 10m
  chart:
    spec:
      chart: clickstack
      reconcileStrategy: ChartVersion
      sourceRef:
        kind: HelmRepository
        name: clickstack-repo
      version: 1.0.0
  values:
    global:
      storageClassName: hcloud-volumes
    hyperdx:
      env:
        - name: BETA_CH_OTEL_JSON_SCHEMA_ENABLED
          value: "true"
      useExistingConfigSecret: true
      existingConfigSecret: hyperdx-external-config
      existingConfigConnectionsKey: connections.json
      existingConfigSourcesKey: sources.json
      otelExporterEndpoint: "http://otel-collector.observability.svc.cluster.local:4318"
      apiKey: 48daf6aa-a32e-4c36-afbb-4b5ffb5ec27f
    clickhouse:
      enabled: false
    otel:
      clickhouseEndpoint: "http://clickhouse-cluster01.clickhouse.svc.cluster.local:8123"
      clickhousePrometheusEndpoint: "clickhouse-operator-altinity-clickhouse-operator-metrics.clickhouse.svc.cluster.local:8888"
      clickhouseDatabase: otel
      clickhouseUser: otel-collector
      env:
        - name: CLICKHOUSE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: clickhouse-opentelemetry-collector-account
              key: password
        - name: OTEL_AGENT_FEATURE_GATE_ARG
          value: "--feature-gates=clickhouse.json"
---
# yaml-language-server: $schema=https://raw.githubusercontent.com/fluxcd-community/flux2-schemas/refs/heads/main/helmrepository-source-v1.json
apiVersion: source.toolkit.fluxcd.io/v1
kind: HelmRepository
metadata:
  name: opentelemetry-repo
  namespace: observability
spec:
  interval: 1m0s
  url: https://open-telemetry.github.io/opentelemetry-helm-charts
---
# yaml-language-server: $schema=https://raw.githubusercontent.com/fluxcd-community/flux2-schemas/refs/heads/main/helmrelease-helm-v2.json
# https://artifacthub.io/packages/helm/opentelemetry-helm/opentelemetry-operator
# https://github.com/open-telemetry/opentelemetry-helm-charts/blob/main/charts/opentelemetry-operator/values.yaml
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: opentelemetry-operator-release
  namespace: observability
spec:
  interval: 10m
  chart:
    spec:
      chart: opentelemetry-operator
      reconcileStrategy: ChartVersion
      sourceRef:
        kind: HelmRepository
        name: opentelemetry-repo
      version: 0.99.2
  values:
    manager:
      operator:
        targetallocator:
          mtls: true
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: opentelemetry-targetallocator
rules:
  - apiGroups: [""]
    resources:
      - nodes
      - nodes/metrics
      - services
      - endpoints
      - pods
      - namespaces
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources:
      - configmaps
    verbs: ["get"]
  - apiGroups:
      - discovery.k8s.io
    resources:
      - endpointslices
    verbs: ["get", "list", "watch"]
  - apiGroups:
      - networking.k8s.io
    resources:
      - ingresses
    verbs: ["get", "list", "watch"]
  - nonResourceURLs: ["/metrics"]
    verbs: ["get"]
  - nonResourceURLs: ["/apis/*"]
    verbs: ["get"]
  - nonResourceURLs: ["/apis"]
    verbs: ["get"]
  - nonResourceURLs: ["/api/*"]
    verbs: ["get"]
  - nonResourceURLs: ["/api"]
    verbs: ["get"]
  - apiGroups:
      - monitoring.coreos.com
    resources:
      - servicemonitors
      - podmonitors
    verbs:
      - "*"
  - apiGroups:
      - cert-manager.io
    resources:
      - issuers
      - certificaterequests
      - certificates
    verbs: ["create", "get", "list", "watch", "update", "patch", "delete"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: opentelemetry-targetallocator
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: opentelemetry-targetallocator
subjects:
  - kind: ServiceAccount
    name: agent-collector-targetallocator
    namespace: observability
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: opentelemetry-agent-collector
rules:
  - apiGroups: [""]
    resources:
      - pods
      - namespaces
    verbs: ["get", "watch", "list"]
  - apiGroups: ["apps"]
    resources:
      - replicasets
    verbs: ["get", "list", "watch"]
  - apiGroups: ["extensions"]
    resources:
      - replicasets
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources:
      - nodes/stats
    verbs: ["get", "watch", "list"]
  - apiGroups: [""]
    resources:
      - pods
    verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: opentelemetry-agent-collector
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: opentelemetry-agent-collector
subjects:
  - kind: ServiceAccount
    name: agent-collector-collector
    namespace: observability
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: opentelemetry-gateway-collector
rules:
  - apiGroups: [""]
    resources:
      - events,
      - namespaces,
      - namespaces/status,
      - nodes,
      - nodes/spec,
      - pods,
      - pods/status,
      - replicationcontrollers,
      - replicationcontrollers/status,
      - resourcequotas,
      - services,
    verbs: ["get", "list", "watch"]
  - apiGroups: ["apps"]
    resources:
      - daemonsets
      - deployments
      - replicasets
      - statefulsets
    verbs: ["get", "list", "watch"]
  - apiGroups: ["extensions"]
    resources:
      - daemonsets
      - deployments
      - replicasets
    verbs: ["get", "list", "watch"]
  - apiGroups: ["batch"]
    resources:
      - jobs
      - cronjobs
    verbs: ["get", "list", "watch"]
  - apiGroups: ["autoscaling"]
    resources:
      - horizontalpodautoscalers
    verbs: ["get", "list", "watch"]
  - apiGroups: ["events.k8s.io"]
    resources:
      - events
    verbs: ["watch", "list"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: opentelemetry-gateway-collector
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: opentelemetry-gateway-collector
subjects:
  - kind: ServiceAccount
    name: gateway-collector-collector
    namespace: observability
---
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: agent-collector
  namespace: observability
spec:
  mode: daemonset
  env:
    - name: MY_POD_IP
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: status.podIP
    - name: K8S_NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    - name: K8S_NODE_IP
      valueFrom:
        fieldRef:
          fieldPath: status.hostIP
  targetAllocator:
    enabled: true
    allocationStrategy: per-node
    prometheusCR:
      enabled: true
      podMonitorSelector: {}
      serviceMonitorSelector: {}
  config:
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
            cors:
              allowed_origins: ["*"]
              allowed_headers: ["*"]
      prometheus:
        config:
          scrape_configs:
            - job_name: otel-collector
              scrape_interval: 10s
              static_configs:
                - targets:
                    - 0.0.0.0:8888
      kubeletstats:
        auth_type: serviceAccount
        collection_interval: 20s
        endpoint: ${env:K8S_NODE_IP}:10250
      receiver_creator/logs:
        discovery:
          default_annotations:
            io.opentelemetry.discovery.logs/enabled: "true"
          enabled: true
        watch_observers:
          - k8s_observer
    extensions:
      health_check:
        endpoint: 0.0.0.0:13133
      k8s_observer:
        auth_type: serviceAccount
        node: ${env:K8S_NODE_NAME}
    processors:
      batch: {}
      k8sattributes:
        extract:
          metadata:
            - k8s.namespace.name
            - k8s.pod.name
            - k8s.pod.uid
            - k8s.node.name
            - k8s.pod.start_time
            - k8s.deployment.name
            - k8s.replicaset.name
            - k8s.replicaset.uid
            - k8s.daemonset.name
            - k8s.daemonset.uid
            - k8s.job.name
            - k8s.job.uid
            - k8s.container.name
            - k8s.cronjob.name
            - k8s.statefulset.name
            - k8s.statefulset.uid
            - container.image.tag
            - container.image.name
            - k8s.cluster.uid
            - service.namespace
            - service.name
            - service.version
            - service.instance.id
          otel_annotations: true
        filter:
          node_from_env_var: K8S_NODE_NAME
        passthrough: false
        pod_association:
          - sources:
              - from: resource_attribute
                name: k8s.pod.ip
          - sources:
              - from: resource_attribute
                name: k8s.pod.uid
          - sources:
              - from: connection
      memory_limiter:
        check_interval: 5s
        limit_percentage: 80
        spike_limit_percentage: 25
    exporters:
      otlp:
        endpoint: clickstack-release-otel-collector.observability.svc.cluster.local:4317
        tls:
          insecure: true
    service:
      extensions:
        - health_check
        - k8s_observer
      pipelines:
        traces:
          receivers: [otlp]
          processors: [k8sattributes, memory_limiter, batch]
          exporters: [otlp]
        metrics:
          receivers: [otlp, prometheus, kubeletstats]
          processors: [k8sattributes, memory_limiter, batch]
          exporters: [otlp]
        logs:
          receivers: [otlp, receiver_creator/logs]
          processors: [k8sattributes, memory_limiter, batch]
          exporters: [otlp]
      telemetry:
        metrics:
          readers:
            - pull:
                exporter:
                  prometheus:
                    host: ${env:MY_POD_IP}
                    port: 8888
---
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: gateway-collector
  namespace: observability
spec:
  mode: deployment
  replicas: 1
  image: otel/opentelemetry-collector-contrib:0.140.1
  env:
    - name: MY_POD_IP
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: status.podIP
    - name: CLICKHOUSE_PASSWORD
      valueFrom:
        secretKeyRef:
          name: clickhouse-opentelemetry-collector-account
          key: password
  args:
    feature-gates: clickhouse.json
  config:
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
            cors:
              allowed_origins: ["*"]
              allowed_headers: ["*"]
      k8s_cluster:
        collection_interval: 10s
      k8sobjects:
        objects:
          - exclude_watch_type:
              - DELETED
            group: events.k8s.io
            mode: watch
            name: events
    extensions:
      health_check:
        endpoint: 0.0.0.0:13133
    processors:
      batch: {}
      memory_limiter:
        check_interval: 5s
        limit_percentage: 80
        spike_limit_percentage: 25
      transform:
        log_statements:
          - context: log
            error_mode: ignore
            statements:
              - set(log.cache, ExtractPatterns(log.body, "(?P<0>(\\{.*\\}))")) where IsString(log.body)
              - merge_maps(log.attributes, ParseJSON(log.cache["0"]), "upsert") where IsMap(log.cache)
              - flatten(log.attributes) where IsMap(log.cache)
              - merge_maps(log.attributes, log.body, "upsert") where IsMap(log.body)
          - conditions:
              - severity_number == 0 and severity_text == ""
            context: log
            error_mode: ignore
            statements:
              - set(log.cache["substr"], log.body.string) where Len(log.body.string) < 256
              - set(log.cache["substr"], Substring(log.body.string, 0, 256)) where Len(log.body.string) >= 256
              - set(log.cache, ExtractPatterns(log.cache["substr"], "(?i)(?P<0>(alert|crit|emerg|fatal|error|err|warn|notice|debug|dbug|trace))"))
              - set(log.severity_number, SEVERITY_NUMBER_FATAL) where IsMatch(log.cache["0"], "(?i)(alert|crit|emerg|fatal)")
              - set(log.severity_text, "fatal") where log.severity_number == SEVERITY_NUMBER_FATAL
              - set(log.severity_number, SEVERITY_NUMBER_ERROR) where IsMatch(log.cache["0"], "(?i)(error|err)")
              - set(log.severity_text, "error") where log.severity_number == SEVERITY_NUMBER_ERROR
              - set(log.severity_number, SEVERITY_NUMBER_WARN) where IsMatch(log.cache["0"], "(?i)(warn|notice)")
              - set(log.severity_text, "warn") where log.severity_number == SEVERITY_NUMBER_WARN
              - set(log.severity_number, SEVERITY_NUMBER_DEBUG) where IsMatch(log.cache["0"], "(?i)(debug|dbug)")
              - set(log.severity_text, "debug") where log.severity_number == SEVERITY_NUMBER_DEBUG
              - set(log.severity_number, SEVERITY_NUMBER_TRACE) where IsMatch(log.cache["0"], "(?i)(trace)")
              - set(log.severity_text, "trace") where log.severity_number == SEVERITY_NUMBER_TRACE
              - set(log.severity_text, "info") where log.severity_number == 0
              - set(log.severity_number, SEVERITY_NUMBER_INFO) where log.severity_number == 0
          - context: log
            error_mode: ignore
            statements:
              - set(log.severity_text, ConvertCase(log.severity_text, "lower"))
    connectors:
      routing/logs:
        default_pipelines:
          - logs/out-default
        error_mode: ignore
        table:
          - context: log
            statement: 'route() where IsMatch(attributes["rr-web.event"], ".*")'
            pipelines:
              - logs/out-rrweb
    exporters:
      clickhouse:
        endpoint: http://clickhouse-cluster01.clickhouse.svc.cluster.local:8123
        database: otel
        username: otel-collector
        password: ${env:CLICKHOUSE_PASSWORD}
        ttl: 720h
        timeout: 5s
        retry_on_failure:
          enabled: true
          initial_interval: 5s
          max_interval: 30s
          max_elapsed_time: 300s
      clickhouse/rrweb:
        endpoint: http://clickhouse-cluster01.clickhouse.svc.cluster.local:8123
        database: otel
        username: otel-collector
        password: ${env:CLICKHOUSE_PASSWORD}
        ttl: 720h
        logs_table_name: hyperdx_sessions
        timeout: 5s
        retry_on_failure:
          enabled: true
          initial_interval: 5s
          max_interval: 30s
          max_elapsed_time: 300s
    service:
      extensions:
        - health_check
      pipelines:
        traces:
          receivers: [otlp]
          processors: [memory_limiter, batch]
          exporters: [clickhouse]
        metrics:
          receivers: [otlp, k8s_cluster]
          processors: [memory_limiter, batch]
          exporters: [clickhouse]
        logs/in:
          receivers: [otlp, k8sobjects]
          exporters: [routing/logs]
        logs/out-default:
          receivers: [routing/logs]
          processors: [memory_limiter, transform, batch]
          exporters: [clickhouse]
        logs/out-rrweb:
          receivers: [routing/logs]
          processors: [memory_limiter, batch]
          exporters: [clickhouse/rrweb]
      telemetry:
        metrics:
          readers:
            - pull:
                exporter:
                  prometheus:
                    host: ${env:MY_POD_IP}
                    port: 8888
# ---
# TODO: go autoinstrumentation (https://opentelemetry.io/docs/platforms/kubernetes/operator/automatic/#go)
# apiVersion: opentelemetry.io/v1alpha1
# kind: Instrumentation
# metadata:
#   name: otel-instrumentation
# spec:
#   exporter:
#     endpoint: http://agent-collector.observability.svc.cluster.local:4317
#   propagators:
#     - tracecontext
#     - baggage
#     - b3
#   go:
#     env:
#       # Required if endpoint is set to 4317.
#       # Go autoinstrumentation uses http/proto by default
#       # so data must be sent to 4318 instead of 4317.
#       - name: OTEL_EXPORTER_OTLP_ENDPOINT
#         value: http://agent-collector.observability.svc.cluster.local:4318
